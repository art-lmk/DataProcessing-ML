# -*- coding: utf-8 -*-
"""DataProcessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QQEBoeiFSMaN6E4l1fxV-aEOu6yJW6Tt

Data processing is the process of tranforming  raw and unclean data into a structured format that can be used for analysis.

The steps of pricessing data are as follows:
  1.Import the necessary libraries and dependencies
  2. Read the data
  3. Sanity check of the data
  4. Exploratory Data Analysis
  5. Missing Value Treatment
  6. Outlier treatments
  7. Duplicates and garbage treatment
  8. Data encoding
"""

#import the necessary librariesand dependencies

import pandas as pd
import numpy as mp
import matplotlib.pyplot as plt
import seaborn as sns
import warnings

warnings.filterwarnings('ignore')

# Read the dataset
df=pd.read_csv("Life Expectancy Data.csv")
df.head()
df.tail()

#Sanity check of the dataset
df.shape
df.info()
df.isnull().sum()

"""Exploratory Data Analysis

Think of it like this: before cooking a meal, you first check your ingredients. Are the veggies fresh? How much rice is there? Any spices missing?

EDA is the same idea, but for data. Itâ€™s the process of exploring your dataset before doing any modeling or predictions.

In simple terms, EDA means:

Look at the shape of your data- How many rows and columns?

Peek inside- Use .head() or .tail() to see the first/last few records.

Check data types - Are columns numbers, text, or dates?

Look for missing or weird values - Any blanks, duplicates, or outliers?

Summarize - Mean, median, min, max, etc. for numeric columns.

Visualize  - Draw charts (histograms, boxplots, scatterplots) to see patterns.

In short, EDA is like getting to know your dataset before you trust it.
"""

#EDA
#Descriptive statistics
df.describe() #checks how our data looks like

#for object analysis(non-numerical data analysis)
df.describe(include='object')

#histogram to understand the distribution
import warnings
warnings.filterwarnings('ignore')
for i in df.select_dtypes(include="number").columns:
    sns.histplot(df[i])
    plt.show()

#boxplot to identify outliers
import warnings
warnings.filterwarnings('ignore')
for i in df.select_dtypes(include="number").columns:
    sns.boxplot(df[i])
    plt.show()

"""Let's use scatter-plots to check whether there's a positive relationship qithin the data or a negative one

"""

for i in df.select_dtypes(include="number").columns:
    # Exclude the 'Life expectancy' column from being plotted against itself
    if i != 'Life expectancy ':
        sns.scatterplot(data=df, x=i, y='Life expectancy ')
        plt.show()

"""Define correlation between the data using heatmaps to interpret the realtion and multicolliniarity"""

# Defining a corelation in discrete values
df.select_dtypes(include="number").corr()

#Heatmaps
b=df.select_dtypes(include="number").corr()
sns.heatmap(b,annot=True)
plt.figure(figsize=(30,30))

#Missing value treatment using KNNImputer from sklearn

from sklearn.impute import KNNImputer

imputer = KNNImputer()

for i in df.select_dtypes(include="number").columns:
    df[i] = imputer.fit_transform(df[[i]])

#let's check whether the missing values have been replaced

df.isnull().sum()

"""Outlier treatments

An outlier is an extreme spot/value where there is an upper side or the lower side of data.
This treatment is used in discrete/continous variables only.
"""

#let's define a wisker function

def wisker(col):
    q1,q3=col.quantile([0.25,0.75])
    iqr=q3-q1
    lower_bound=q1-(1.5*iqr)
    upper_bound=q3+(1.5*iqr)
    return lower_bound,upper_bound
wisker(df['GDP'])

import numpy as np
for i in ['GDP','Total expenditure', ' thinness  1-19 years']:
    lower_bound,upper_bound=wisker(df[i])
    df[i]=np.where(df[i]>upper_bound,upper_bound,df[i])
    df[i]=np.where(df[i]<lower_bound,lower_bound,df[i])

#to show the boxplots with no outliers
for i in ['GDP','Total expenditure', ' thinness  1-19 years']:
    sns.boxplot(df[i])
    plt.show()

"""Data encoding

This is converting object variables into numerals
For the data to fit the model,it is supposed to be encoded with numbers
Data encodingis done in 2 ways:
  1. Label encoding
  2. Hot encoding using the pd.getdummies
"""

dummy= pd.get_dummies(data=df,columns=['Country', 'Status'],drop_first="True")
dummy
